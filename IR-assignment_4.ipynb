{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3411,"sourceType":"datasetVersion","datasetId":1988},{"sourceId":818994,"sourceType":"datasetVersion","datasetId":428389},{"sourceId":8169274,"sourceType":"datasetVersion","datasetId":4834463}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas nltk # ONE TIMER","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-20T06:11:03.921242Z","iopub.execute_input":"2024-04-20T06:11:03.921706Z","iopub.status.idle":"2024-04-20T06:11:40.258492Z","shell.execute_reply.started":"2024-04-20T06:11:03.921671Z","shell.execute_reply":"2024-04-20T06:11:40.257004Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"%pwd","metadata":{"execution":{"iopub.status.busy":"2024-04-20T06:09:32.093480Z","iopub.execute_input":"2024-04-20T06:09:32.093887Z","iopub.status.idle":"2024-04-20T06:09:32.102807Z","shell.execute_reply.started":"2024-04-20T06:09:32.093854Z","shell.execute_reply":"2024-04-20T06:09:32.101530Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"%cd ..\n!ls -a","metadata":{"execution":{"iopub.status.busy":"2024-04-20T06:09:44.732277Z","iopub.execute_input":"2024-04-20T06:09:44.733023Z","iopub.status.idle":"2024-04-20T06:09:45.823770Z","shell.execute_reply.started":"2024-04-20T06:09:44.732989Z","shell.execute_reply":"2024-04-20T06:09:45.822532Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle\n.  ..  input  lib  working\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd input","metadata":{"execution":{"iopub.status.busy":"2024-04-19T22:27:05.032315Z","iopub.execute_input":"2024-04-19T22:27:05.033353Z","iopub.status.idle":"2024-04-19T22:27:05.039951Z","shell.execute_reply.started":"2024-04-19T22:27:05.033315Z","shell.execute_reply":"2024-04-19T22:27:05.038717Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/kaggle/input\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls -a","metadata":{"execution":{"iopub.status.busy":"2024-04-20T04:04:18.713576Z","iopub.execute_input":"2024-04-20T04:04:18.714413Z","iopub.status.idle":"2024-04-20T04:04:19.810481Z","shell.execute_reply.started":"2024-04-20T04:04:18.714377Z","shell.execute_reply":"2024-04-20T04:04:19.809061Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":".  ..  .virtual_documents  state.db\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd working","metadata":{"execution":{"iopub.status.busy":"2024-04-20T06:10:05.814611Z","iopub.execute_input":"2024-04-20T06:10:05.815043Z","iopub.status.idle":"2024-04-20T06:10:05.822312Z","shell.execute_reply.started":"2024-04-20T06:10:05.815004Z","shell.execute_reply":"2024-04-20T06:10:05.821011Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntry:\n    df = pd.read_csv('/kaggle/input/reviews-dataset-input-file/Reviews.csv', engine='python', on_bad_lines='skip')\n    print(\"'Reviews.csv' file read successfully.\\n\")\n    print(df.head())\nexcept Exception as e:\n    print(\"ERROR: Failed to read dataset file 'Reviews.csv':\", e)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T06:13:33.262656Z","iopub.execute_input":"2024-04-20T06:13:33.263090Z","iopub.status.idle":"2024-04-20T06:13:45.934388Z","shell.execute_reply.started":"2024-04-20T06:13:33.263055Z","shell.execute_reply":"2024-04-20T06:13:45.932090Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"'Reviews.csv' file read successfully.\n\n   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \n0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n2  \"Delight\" says it all  This is a confection that has been around a fe...  \n3         Cough Medicine  If you are looking for the secret ingredient i...  \n4            Great taffy  Great taffy at a great price.  There was a wid...  \n","output_type":"stream"}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-20T06:14:59.124067Z","iopub.execute_input":"2024-04-20T06:14:59.124460Z","iopub.status.idle":"2024-04-20T06:14:59.132449Z","shell.execute_reply.started":"2024-04-20T06:14:59.124431Z","shell.execute_reply":"2024-04-20T06:14:59.131188Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(568454, 10)"},"metadata":{}}]},{"cell_type":"code","source":"# We will work on subset of data (~50000 rows)\ndf = df.iloc[:50000, :]\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T07:07:31.648669Z","iopub.execute_input":"2024-04-20T07:07:31.649135Z","iopub.status.idle":"2024-04-20T07:07:31.668026Z","shell.execute_reply.started":"2024-04-20T07:07:31.649101Z","shell.execute_reply":"2024-04-20T07:07:31.666700Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n6   7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n7   8  B006K2ZZ7K  A3JRGQVEQN31IQ               Pamela G. Williams   \n8   9  B000E7L2R4  A1MZYO9TZK0BBI                         R. James   \n9  10  B00171APVA  A21BT40VZCCYT4                    Carol A. Reed   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n5                     0                       0      4  1342051200   \n6                     0                       0      5  1340150400   \n7                     0                       0      5  1336003200   \n8                     1                       1      5  1322006400   \n9                     0                       0      5  1351209600   \n\n                      Summary  \\\n0       good quality dog food   \n1                  advertised   \n2                 delight say   \n3              cough medicine   \n4                 great taffy   \n5                  nice taffy   \n6  great good expensive brand   \n7       wonderful tasty taffy   \n8                  yay barley   \n9            healthy dog food   \n\n                                                Text  \n0  bought several vitality canned dog food produc...  \n1  product arrived labeled jumbo salted peanutsth...  \n2  confection around century light pillowy citrus...  \n3  looking secret ingredient robitussin believe f...  \n4  great taffy great price wide assortment yummy ...  \n5  got wild hair taffy ordered five pound bag taf...  \n6  saltwater taffy great flavor soft chewy candy ...  \n7  taffy good soft chewy flavor amazing would def...  \n8  right im mostly sprouting cat eat grass love r...  \n9  healthy dog food good digestion also good smal...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>good quality dog food</td>\n      <td>bought several vitality canned dog food produc...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>advertised</td>\n      <td>product arrived labeled jumbo salted peanutsth...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>delight say</td>\n      <td>confection around century light pillowy citrus...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>cough medicine</td>\n      <td>looking secret ingredient robitussin believe f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>great taffy</td>\n      <td>great taffy great price wide assortment yummy ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>B006K2ZZ7K</td>\n      <td>ADT0SRK1MGOEU</td>\n      <td>Twoapennything</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1342051200</td>\n      <td>nice taffy</td>\n      <td>got wild hair taffy ordered five pound bag taf...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1SP2KVKFXXRU1</td>\n      <td>David C. Sullivan</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1340150400</td>\n      <td>great good expensive brand</td>\n      <td>saltwater taffy great flavor soft chewy candy ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>B006K2ZZ7K</td>\n      <td>A3JRGQVEQN31IQ</td>\n      <td>Pamela G. Williams</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1336003200</td>\n      <td>wonderful tasty taffy</td>\n      <td>taffy good soft chewy flavor amazing would def...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>B000E7L2R4</td>\n      <td>A1MZYO9TZK0BBI</td>\n      <td>R. James</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1322006400</td>\n      <td>yay barley</td>\n      <td>right im mostly sprouting cat eat grass love r...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>B00171APVA</td>\n      <td>A21BT40VZCCYT4</td>\n      <td>Carol A. Reed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1351209600</td>\n      <td>healthy dog food</td>\n      <td>healthy dog food good digestion also good smal...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\nnltk.download('punkt')\nnltk.download('wordnet')\nprint(\"SUCCESS\")","metadata":{"execution":{"iopub.status.busy":"2024-04-20T07:04:53.760129Z","iopub.execute_input":"2024-04-20T07:04:53.760610Z","iopub.status.idle":"2024-04-20T07:05:35.347392Z","shell.execute_reply.started":"2024-04-20T07:04:53.760555Z","shell.execute_reply":"2024-04-20T07:05:35.345690Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\nSUCCESS\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport string\n\ndef preprocess_text(text):\n    try:\n\n        # Check if the text is a string\n        if not isinstance(text, str):\n            return \"\"  # Return empty string if not\n\n        # Convert text to lower case\n        text = text.lower()\n\n        # Remove punctuation\n        text = text.translate(str.maketrans('', '', string.punctuation))\n\n        # Tokenization\n        tokens = nltk.tokenize.word_tokenize(text)\n\n        # Remove stopwords\n        stop_words = set(stopwords.words('english'))\n        tokens = [word for word in tokens if word not in stop_words]\n\n        # Remove blank spaces from prefix/suffix (if any)\n        tokens = [word for word in tokens if word.strip()]\n\n        # Lemmatization\n        lemmatizer = WordNetLemmatizer()\n        lemmatized_text = ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n\n        return lemmatized_text\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n        return text\n\n# Preprocessing 'Text' and 'Summary' columns\ndf['Text'] = df['Text'].apply(preprocess_text)\ndf['Summary'] = df['Summary'].apply(preprocess_text)\n\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T07:07:36.111803Z","iopub.execute_input":"2024-04-20T07:07:36.112264Z","iopub.status.idle":"2024-04-20T07:07:42.871445Z","shell.execute_reply.started":"2024-04-20T07:07:36.112231Z","shell.execute_reply":"2024-04-20T07:07:42.870271Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n6   7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n7   8  B006K2ZZ7K  A3JRGQVEQN31IQ               Pamela G. Williams   \n8   9  B000E7L2R4  A1MZYO9TZK0BBI                         R. James   \n9  10  B00171APVA  A21BT40VZCCYT4                    Carol A. Reed   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n5                     0                       0      4  1342051200   \n6                     0                       0      5  1340150400   \n7                     0                       0      5  1336003200   \n8                     1                       1      5  1322006400   \n9                     0                       0      5  1351209600   \n\n                      Summary  \\\n0       good quality dog food   \n1                  advertised   \n2                 delight say   \n3              cough medicine   \n4                 great taffy   \n5                  nice taffy   \n6  great good expensive brand   \n7       wonderful tasty taffy   \n8                  yay barley   \n9            healthy dog food   \n\n                                                Text  \n0  bought several vitality canned dog food produc...  \n1  product arrived labeled jumbo salted peanutsth...  \n2  confection around century light pillowy citrus...  \n3  looking secret ingredient robitussin believe f...  \n4  great taffy great price wide assortment yummy ...  \n5  got wild hair taffy ordered five pound bag taf...  \n6  saltwater taffy great flavor soft chewy candy ...  \n7  taffy good soft chewy flavor amazing would def...  \n8  right im mostly sprouting cat eat grass love r...  \n9  healthy dog food good digestion also good smal...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>good quality dog food</td>\n      <td>bought several vitality canned dog food produc...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>advertised</td>\n      <td>product arrived labeled jumbo salted peanutsth...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>delight say</td>\n      <td>confection around century light pillowy citrus...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>cough medicine</td>\n      <td>looking secret ingredient robitussin believe f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>great taffy</td>\n      <td>great taffy great price wide assortment yummy ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>B006K2ZZ7K</td>\n      <td>ADT0SRK1MGOEU</td>\n      <td>Twoapennything</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1342051200</td>\n      <td>nice taffy</td>\n      <td>got wild hair taffy ordered five pound bag taf...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1SP2KVKFXXRU1</td>\n      <td>David C. Sullivan</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1340150400</td>\n      <td>great good expensive brand</td>\n      <td>saltwater taffy great flavor soft chewy candy ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>B006K2ZZ7K</td>\n      <td>A3JRGQVEQN31IQ</td>\n      <td>Pamela G. Williams</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1336003200</td>\n      <td>wonderful tasty taffy</td>\n      <td>taffy good soft chewy flavor amazing would def...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>B000E7L2R4</td>\n      <td>A1MZYO9TZK0BBI</td>\n      <td>R. James</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1322006400</td>\n      <td>yay barley</td>\n      <td>right im mostly sprouting cat eat grass love r...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>B00171APVA</td>\n      <td>A21BT40VZCCYT4</td>\n      <td>Carol A. Reed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1351209600</td>\n      <td>healthy dog food</td>\n      <td>healthy dog food good digestion also good smal...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install transformers torch --upgrade","metadata":{"execution":{"iopub.status.busy":"2024-04-20T07:22:49.059071Z","iopub.execute_input":"2024-04-20T07:22:49.059534Z","iopub.status.idle":"2024-04-20T07:27:39.540976Z","shell.execute_reply.started":"2024-04-20T07:22:49.059502Z","shell.execute_reply":"2024-04-20T07:27:39.539287Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a1d2af04820>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a1d2af04b20>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a1d2af04cd0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a1d2af04e80>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a1d2af05030>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers/\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a1d2af6c700>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torch/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a1d2af6cc40>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torch/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a1d2af6cdf0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torch/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a1d2af6cfa0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torch/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a1d2af6d150>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torch/\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2Model\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-04-20T07:11:03.145095Z","iopub.execute_input":"2024-04-20T07:11:03.145490Z","iopub.status.idle":"2024-04-20T07:11:11.535217Z","shell.execute_reply.started":"2024-04-20T07:11:03.145452Z","shell.execute_reply":"2024-04-20T07:11:11.533987Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Verify GPU availability\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\n# Initialize tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2Model.from_pretrained('gpt2').to(device)\n\nprint(\"Tokenizer and model initialized successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-20T07:11:11.536663Z","iopub.execute_input":"2024-04-20T07:11:11.537395Z","iopub.status.idle":"2024-04-20T07:13:32.150380Z","shell.execute_reply.started":"2024-04-20T07:11:11.537351Z","shell.execute_reply":"2024-04-20T07:13:32.148787Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize tokenizer and model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mGPT2Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT2Model\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer and model initialized successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2070\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2064\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2065\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2066\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2067\u001b[0m     )\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 2070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2072\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2073\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2074\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2075\u001b[0m     )\n\u001b[1;32m   2077\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2078\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n","\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'gpt2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'gpt2' is the correct path to a directory containing all relevant files for a GPT2Tokenizer tokenizer."],"ename":"OSError","evalue":"Can't load tokenizer for 'gpt2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'gpt2' is the correct path to a directory containing all relevant files for a GPT2Tokenizer tokenizer.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}